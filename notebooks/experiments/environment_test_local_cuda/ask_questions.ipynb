{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-10T21:50:51.668975Z",
     "start_time": "2025-06-10T21:50:51.473504Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import pprint\n",
    "current_dir = Path(os.getcwd()).resolve()\n",
    "if current_dir.name == \"LLMPolReasonEval\": # uruchomione w Jupyter Lab\n",
    "    project_root = current_dir\n",
    "else:  # uruchomione w PyCharm\n",
    "    project_root = current_dir.parents[2]\n",
    "print(f\"Project root: {project_root}\")\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "from llm_pol_reason_eval.qa_engine.llm_qa_engine import LLMQAEngine\n",
    "from llm_pol_reason_eval.qa_engine.inference_client import HuggingFaceClient"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Project root: C:\\Users\\piotr\\PycharmProjects\\LLMPolReasonEval\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T21:50:52.140903Z",
     "start_time": "2025-06-10T21:50:51.938197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EXPERIMENT_NAME = \"qwen-thinking-matura\"\n",
    "\n",
    "# Wczytaj pliki konfiguracyjne\n",
    "RUN_CONFIG_FILE = \"config/runs/answer_generation_run.yaml\"\n",
    "MODELS_CONFIG_FILE = \"config/models.yaml\"\n",
    "\n",
    "with open(project_root / RUN_CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "    run_config = yaml.safe_load(f)['experiments'][EXPERIMENT_NAME]\n",
    "\n",
    "with open(project_root / MODELS_CONFIG_FILE, 'r', encoding='utf-8') as f:\n",
    "    models_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Uruchamiam eksperyment: {run_config.get('task_name')}\")"
   ],
   "id": "29c65e6075de8453",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uruchamiam eksperyment: Qwen3 1.7B - Odpowiedzi z myśleniem 'krok po kroku'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T21:50:59.413010Z",
     "start_time": "2025-06-10T21:50:53.192588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_key = run_config['model']\n",
    "model_cfg = models_config[model_key]\n",
    "\n",
    "run_overrides = run_config.get(\"param_overrides\", {})\n",
    "final_gen_params = model_cfg['generation_params'].copy()\n",
    "final_gen_params.update(run_overrides.get('default', {}))\n",
    "\n",
    "# Inicjalizacja klienta inferencji - to może potrwać chwilę\n",
    "inference_client = HuggingFaceClient(\n",
    "    model_path=model_cfg['path'],\n",
    "    default_generation_params=final_gen_params\n",
    ")\n",
    "\n",
    "engine = LLMQAEngine(\n",
    "    model_name=model_key,\n",
    "    model_path=model_cfg['path'],\n",
    "    inference_client=inference_client\n",
    ")"
   ],
   "id": "b971ec1938bb1381",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceClient: Inicjalizacja modelu Qwen/Qwen3-1.7B na urządzeniu: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1900f7b6367c46e4af8903d83afe4ff6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFaceClient: Domyślna konfiguracja generowania: GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"max_new_tokens\": 768,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.95\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T21:51:08.621894Z",
     "start_time": "2025-06-10T21:51:08.265965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dataset_path = project_root / run_config['input_dataset']\n",
    "\n",
    "# Użyjemy query, żeby nie przetwarzać całego datasetu podczas testów w notatniku\n",
    "# Możesz usunąć `query`, aby przetworzyć cały plik\n",
    "target_question_ids = [\"MPOP-P1-100-A-2405_zadanie_14\", \"EPOP-P1-100-2305_zad_1\"]\n",
    "query = lambda q: q.get(\"question_id\") in target_question_ids\n",
    "\n",
    "per_type_params = run_config.get(\"param_overrides\", {}).get('per_type')\n",
    "\n",
    "results = engine.generate_answers(\n",
    "    dataset_filepath=str(input_dataset_path),\n",
    "    param_overrides=run_overrides,\n",
    "    query=query\n",
    ")"
   ],
   "id": "6f5164e1b3fcefae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Przetwarzanie batcha | Typ: closed_MTF, Pytania: 1 ---\n"
     ]
    },
    {
     "ename": "TemplateNotFound",
     "evalue": "default\\system.jinja2",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTemplateNotFound\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      6\u001B[39m query = \u001B[38;5;28;01mlambda\u001B[39;00m q: q.get(\u001B[33m\"\u001B[39m\u001B[33mquestion_id\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01min\u001B[39;00m target_question_ids\n\u001B[32m      8\u001B[39m per_type_params = run_config.get(\u001B[33m\"\u001B[39m\u001B[33mparam_overrides\u001B[39m\u001B[33m\"\u001B[39m, {}).get(\u001B[33m'\u001B[39m\u001B[33mper_type\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m results = \u001B[43mengine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_answers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_filepath\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_dataset_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparam_overrides\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_overrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LLMPolReasonEval\\src\\llm_pol_reason_eval\\qa_engine\\llm_qa_engine.py:48\u001B[39m, in \u001B[36mLLMQAEngine.generate_answers\u001B[39m\u001B[34m(self, dataset_filepath, batch_size, query, param_overrides)\u001B[39m\n\u001B[32m     44\u001B[39m question_ids_in_batch = \u001B[38;5;28mlist\u001B[39m(batch_data[\u001B[33m'\u001B[39m\u001B[33mquestions\u001B[39m\u001B[33m'\u001B[39m].keys())\n\u001B[32m     46\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m--- Przetwarzanie batcha | Typ: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mq_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, Pytania: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(question_ids_in_batch)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m ---\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m messages = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprompt_manager\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_question_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m template_args = {}\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33menable_thinking\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m param_overrides.get(\u001B[33m'\u001B[39m\u001B[33mdefault\u001B[39m\u001B[33m'\u001B[39m, {}):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LLMPolReasonEval\\src\\llm_pol_reason_eval\\prompts\\prompt_manager.py:28\u001B[39m, in \u001B[36mPromptManager.get_question_prompt\u001B[39m\u001B[34m(self, model_name, batch_data)\u001B[39m\n\u001B[32m     25\u001B[39m system_template_path = \u001B[38;5;28mself\u001B[39m._get_template_path(model_name, \u001B[33m\"\u001B[39m\u001B[33msystem.jinja2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     26\u001B[39m user_template_path = \u001B[38;5;28mself\u001B[39m._get_template_path(model_name, \u001B[33m\"\u001B[39m\u001B[33mbase_question_prompt.jinja2\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m system_content = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43msystem_template_path\u001B[49m\u001B[43m)\u001B[49m.render()\n\u001B[32m     29\u001B[39m user_content = \u001B[38;5;28mself\u001B[39m.env.get_template(user_template_path).render(**batch_data)\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m [{\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33msystem\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: system_content}, {\u001B[33m\"\u001B[39m\u001B[33mrole\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: user_content}]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LLMPolReasonEval\\.venv\\Lib\\site-packages\\jinja2\\environment.py:1016\u001B[39m, in \u001B[36mEnvironment.get_template\u001B[39m\u001B[34m(self, name, parent, globals)\u001B[39m\n\u001B[32m   1013\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m parent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1014\u001B[39m     name = \u001B[38;5;28mself\u001B[39m.join_path(name, parent)\n\u001B[32m-> \u001B[39m\u001B[32m1016\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LLMPolReasonEval\\.venv\\Lib\\site-packages\\jinja2\\environment.py:975\u001B[39m, in \u001B[36mEnvironment._load_template\u001B[39m\u001B[34m(self, name, globals)\u001B[39m\n\u001B[32m    971\u001B[39m             template.globals.update(\u001B[38;5;28mglobals\u001B[39m)\n\u001B[32m    973\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m template\n\u001B[32m--> \u001B[39m\u001B[32m975\u001B[39m template = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmake_globals\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    977\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    978\u001B[39m     \u001B[38;5;28mself\u001B[39m.cache[cache_key] = template\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LLMPolReasonEval\\.venv\\Lib\\site-packages\\jinja2\\loaders.py:126\u001B[39m, in \u001B[36mBaseLoader.load\u001B[39m\u001B[34m(self, environment, name, globals)\u001B[39m\n\u001B[32m    122\u001B[39m     \u001B[38;5;28mglobals\u001B[39m = {}\n\u001B[32m    124\u001B[39m \u001B[38;5;66;03m# first we try to get the source for this template together\u001B[39;00m\n\u001B[32m    125\u001B[39m \u001B[38;5;66;03m# with the filename and the uptodate function.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m source, filename, uptodate = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_source\u001B[49m\u001B[43m(\u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[38;5;66;03m# try to load the code from the bytecode cache if there is a\u001B[39;00m\n\u001B[32m    129\u001B[39m \u001B[38;5;66;03m# bytecode cache configured.\u001B[39;00m\n\u001B[32m    130\u001B[39m bcc = environment.bytecode_cache\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LLMPolReasonEval\\.venv\\Lib\\site-packages\\jinja2\\loaders.py:197\u001B[39m, in \u001B[36mFileSystemLoader.get_source\u001B[39m\u001B[34m(self, environment, template)\u001B[39m\n\u001B[32m    194\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_source\u001B[39m(\n\u001B[32m    195\u001B[39m     \u001B[38;5;28mself\u001B[39m, environment: \u001B[33m\"\u001B[39m\u001B[33mEnvironment\u001B[39m\u001B[33m\"\u001B[39m, template: \u001B[38;5;28mstr\u001B[39m\n\u001B[32m    196\u001B[39m ) -> t.Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m, t.Callable[[], \u001B[38;5;28mbool\u001B[39m]]:\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m     pieces = \u001B[43msplit_template_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemplate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    199\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m searchpath \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.searchpath:\n\u001B[32m    200\u001B[39m         \u001B[38;5;66;03m# Use posixpath even on Windows to avoid \"drive:\" or UNC\u001B[39;00m\n\u001B[32m    201\u001B[39m         \u001B[38;5;66;03m# segments breaking out of the search directory.\u001B[39;00m\n\u001B[32m    202\u001B[39m         filename = posixpath.join(searchpath, *pieces)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LLMPolReasonEval\\.venv\\Lib\\site-packages\\jinja2\\loaders.py:36\u001B[39m, in \u001B[36msplit_template_path\u001B[39m\u001B[34m(template)\u001B[39m\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m piece \u001B[38;5;129;01min\u001B[39;00m template.split(\u001B[33m\"\u001B[39m\u001B[33m/\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m     31\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m     32\u001B[39m         os.path.sep \u001B[38;5;129;01min\u001B[39;00m piece\n\u001B[32m     33\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m (os.path.altsep \u001B[38;5;129;01mand\u001B[39;00m os.path.altsep \u001B[38;5;129;01min\u001B[39;00m piece)\n\u001B[32m     34\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m piece == os.path.pardir\n\u001B[32m     35\u001B[39m     ):\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m TemplateNotFound(template)\n\u001B[32m     37\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m piece \u001B[38;5;129;01mand\u001B[39;00m piece != \u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     38\u001B[39m         pieces.append(piece)\n",
      "\u001B[31mTemplateNotFound\u001B[39m: default\\system.jinja2"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"--- WYGENEROWANE ODPOWIEDZI ---\")\n",
    "pprint.pprint(results)\n",
    "\n",
    "# Zapisz wyniki\n",
    "output_dir = project_root / run_config['output_dir']\n",
    "output_path = output_dir / f\"answers_notebook_{EXPERIMENT_NAME}.json\"\n",
    "engine.save_results(output_filepath=str(output_path))"
   ],
   "id": "d314977f18884253"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "346081ce32e22e24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7f676f37987b1464"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
