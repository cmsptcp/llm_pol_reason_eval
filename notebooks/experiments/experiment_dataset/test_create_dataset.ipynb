{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T20:42:28.279155Z",
     "start_time": "2025-06-15T20:42:28.117234Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, UTC\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_dir = Path(os.getcwd()).resolve()\n",
    "if current_dir.name == \"LLMPolReasonEval\": # uruchomione w Jupyter Lab\n",
    "    project_root = current_dir\n",
    "else:  # uruchomione w PyCharm\n",
    "    project_root = current_dir.parents[2]\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "from llm_pol_reason_eval.question_processing.dataset_manager import DatasetManager\n",
    "\n",
    "if load_dotenv(os.path.join(project_root, '.env')):\n",
    "    print (f\"Loaded environment variables from {project_root / '.env'}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\piotr\\PycharmProjects\\LLMPolReasonEval\n",
      "Loaded environment variables from C:\\Users\\piotr\\PycharmProjects\\LLMPolReasonEval\\.env\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:02:41.288882Z",
     "start_time": "2025-06-15T14:02:41.241795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_raw_path = project_root / \"data\" / \"dataset_raw\"\n",
    "output_dir = project_root / \"data\" / \"dataset\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "12c010f7d882b271",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:02:57.412781Z",
     "start_time": "2025-06-15T14:02:57.340740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicjalizacja managera i ładowanie danych\n",
    "dataset_manager = DatasetManager()\n",
    "for json_file in dataset_raw_path.rglob(\"*.json\"):\n",
    "    if \"MPOP-P1-100-2412-gemini25pro-2025-06-14T20-55-00Z.json\" in str(json_file):\n",
    "        print(f\"Pomijam plik: {json_file}\")\n",
    "        continue\n",
    "    dataset_manager.add_data_from_json_file(str(json_file))\n",
    "\n",
    "# Generowanie ścieżki wyjściowej z timestampem ISO 8601\n",
    "iso_timestamp = datetime.now(UTC).replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\").replace(\":\", \"-\")\n",
    "output_filename = f\"polski_matura_dataset_{iso_timestamp}.json\"\n",
    "output_path = output_dir / output_filename\n",
    "\n",
    "# Zapis datasetu\n",
    "dataset_manager.save_all_data_to_json_file(str(output_path))\n",
    "print(f\"Zapisano dataset do: {output_path}\")"
   ],
   "id": "dc09175481e5ce86",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:03:04.758264Z",
     "start_time": "2025-06-15T14:03:04.709106Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_manager.get_stats()",
   "id": "9ccd4867f90244c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_category_stats': [('matura_język_polski', 267)],\n",
       " 'question_type_stats': [('open_text', 179),\n",
       "  ('closed_MTF', 28),\n",
       "  ('closed_MCQ', 16),\n",
       "  ('open_essay', 13),\n",
       "  ('open_summary', 10),\n",
       "  ('open_poetry_interpretation', 8),\n",
       "  ('closed_MRQ', 7),\n",
       "  ('open_synthesis', 6)]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:37:30.220262Z",
     "start_time": "2025-06-15T14:37:30.155865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question_batch_generator = dataset_manager.generate_question_batches(batch_size=1,\n",
    "                                          with_contexts=True,\n",
    "                                          by_q_category=True,\n",
    "                                          by_q_type=True\n",
    "                                          )\n"
   ],
   "id": "70b45f5e0cd79a9e",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:37:30.670133Z",
     "start_time": "2025-06-15T14:37:30.619003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "for batch in question_batch_generator:\n",
    "    questions = batch.get(\"questions\", {})\n",
    "    contexts = batch.get(\"contexts\", {})\n",
    "    metadata = batch.get(\"metadata\", {})\n",
    "    print(f\"Batch size: {len(questions)} questions, {len(contexts)} contexts, question_type: {metadata.get('question_type')}, question_category: {metadata.get('category')}\")\n",
    "    for question in questions:\n",
    "        print(questions[question][\"question_text\"])\n",
    "        # for context_id in questions[question][\"context_ids\"]:\n",
    "        #    print(f\"  Context ID: {context_id}\")\n",
    "        #    print(f\"  Context Text: {contexts[context_id].get(\"context_content\")}\")\n",
    "    break  # Przerwij po pierwszym batchu dla testów"
   ],
   "id": "f1eaad377c065dff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1 questions, 1 contexts, question_type: closed_MTF, question_category: matura_język_polski\n",
      "Oceń prawdziwość poniższych stwierdzeń odnoszących się do tekstu Ewy Kołodziejek. Zaznacz P, jeśli stwierdzenie jest prawdziwe, albo F - jeśli jest fałszywe.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:43:04.936516Z",
     "start_time": "2025-06-15T20:43:04.884303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mpop_2412_json_path = project_root / \"data\" / \"dataset\" / \"MPOP-P1-100-2412-gemini25pro-2025-06-14T20-55-00Z.json\"\n",
    "dataset_manager_mpop_2412 = DatasetManager()"
   ],
   "id": "2d78158e875cf181",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:43:11.901976Z",
     "start_time": "2025-06-15T20:43:11.844792Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_manager_mpop_2412.add_data_from_json_file(mpop_2412_json_path)",
   "id": "df23368be0f828ca",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:43:24.466824Z",
     "start_time": "2025-06-15T20:43:24.411110Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_manager_mpop_2412.get_stats()",
   "id": "a4656d40d2f09ae7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_category_stats': [('matura_język_polski', 16)],\n",
       " 'question_type_stats': [('open_text', 13),\n",
       "  ('closed_MTF', 2),\n",
       "  ('open_synthesis', 1)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6674e74d272b0bc5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
